#!/usr/bin/env python
# coding: utf-8

import re
import os
import csv
import sys
import glob
import tempfile
import fileinput
import subprocess
import traceback
from models import SentenceParse
from sqlalchemy.orm.exc import NoResultFound
from utils import count_lmk_phrases, printcolors
from nltk.tree import ParentedTree

def chunks(l, n):
    return [l[i:i+n] for i in range(0, len(l), n)]

def parse_sentences(ss, parser_path='../bllip-parser', n=5, threads=2):
    """parse sentences with the charniak parser"""
    # create a temporary file and write the sentences in it
    temp = tempfile.NamedTemporaryFile()
    for s in ss:
        temp.write('<s> %s </s>\n' % s)
    temp.flush()
    # where am i?
    # prev_path = os.getcwd()
    # get into the charniak parser directory
    # os.chdir(parser_path)
    # call the parser
    proc = subprocess.Popen(['./parse.sh', '-N%i' % n, temp.name],
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE)
    # capture output
    output = proc.communicate()[0]
    # return to where i was
    # os.chdir(prev_path)
    # get rid of temporary file
    temp.close()
    # return the parse trees
    return chunks([l for l in output.splitlines() if l[:3] == '(S1'],n)




def modify_parses(trees, tregex_path='stanford-tregex',
                         surgery_path='surgery'):
    """modify parse trees using tsurgeon"""
    # write trees to temp file
    n = len(trees[0])
    temp = tempfile.NamedTemporaryFile()
    for t in trees:
        for tt in t:
            temp.write(tt + '\n')
    temp.flush()

    # tregex jar location
    jar = os.path.join(tregex_path, 'stanford-tregex.jar')
    tsurgeon = 'edu.stanford.nlp.trees.tregex.tsurgeon.Tsurgeon'
    # surgery scripts
    surgery = sorted(glob.glob(os.path.join(surgery_path, '*')))
    proc = subprocess.Popen(['java', '-mx100m', '-cp', jar, tsurgeon,
                             '-s', '-treeFile', temp.name] + surgery,
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE)
    # get output
    output = proc.communicate()[0]
    # delete temp file
    temp.close()
    # return modified parse trees
    return chunks(output.splitlines(),n)



def parse_generator_data(datafile):
    """parse a file with data generated by table2d generator"""
    xlocs, ylocs, sentences = [], [], []
    # this is how each observation looks like
    # for example: Vec2(5.31, 5.11); on the table
    pattern = r'^Vec2\((?P<x>-?[0-9.]+), (?P<y>-?[0-9.]+)\); (?P<sent>.+)$'
    for line in datafile:
        match = re.match(pattern, line)
        if match:
            xlocs.append(float(match.group('x')))
            ylocs.append(float(match.group('y')))
            sentences.append(match.group('sent'))
    return xlocs, ylocs, sentences


class ParseError(RuntimeError):
    pass

def get_modparse(sentence):
    """returns the modified parse tree for a sentence"""
    sp_db = SentenceParse.get_sentence_parse(sentence)
    try:
        res = sp_db.all()[0]
        parsetree = res.original_parse
        modparsetree = res.modified_parse
    except:
        print "parse.py: 104: " + sentence
        parses = parse_sentences([sentence])
        if len(parses) == 0:
            raise ParseError(printcolors.WARNING + ('ParseError: a sentence was empty'))

        modparses = modify_parses(parses)
        for i,chunk in enumerate(modparses[:]):
            for j,modparse in enumerate(chunk):
                if 'LANDMARK-PHRASE' in modparse:
                    modparses[i] = modparse
                    parses[i] = parses[i][j]
                    break
            if isinstance(modparses[i],list):
                modparses[i] = modparses[i][0]
                parses[i] = parses[i][0]

        parsetree = parses[0]
        modparsetree = modparses[0]
        try:
            SentenceParse.add_sentence_parse(sentence, parsetree, modparsetree)
        except Exception as e:
            print e

    if count_lmk_phrases(ParentedTree.parse(modparsetree)) < 1:
        raise ParseError(printcolors.WARNING + ('ParseError: Parse contained no Landmark phrase.\nSentence: %s\nParse: %s\nModparse: %s' % (sentence,parsetree,modparsetree)))

    return parsetree, modparsetree



if __name__ == '__main__':
    # parse data from file or stdin
    xlocs, ylocs, sentences = parse_generator_data(fileinput.input())
    # parse sentences
    parses = parse_sentences(sentences)
    # write csv data to stdout
    writer = csv.writer(sys.stdout, lineterminator='\n')
    writer.writerow(['xloc', 'yloc', 'sentence', 'parse'])
    for row in zip(xlocs, ylocs, sentences, parses):
        writer.writerow(row)
